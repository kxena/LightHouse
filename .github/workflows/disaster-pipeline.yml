name: Disaster Tweet Pipeline

on:
  # Run twice a day at 12 AM and 12 PM CST
  schedule:
    - cron: '0 0,12 * * *'
  
  # Allow manual runs from GitHub UI
  workflow_dispatch:

jobs:
  run-pipeline:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        cd backend
        pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Verify model files exist
      run: |
        cd backend/xgboost_classifier
        ls -la xgboost_model*.joblib xgboost_vectorizer*.joblib xgboost_config*.json
    
    - name: Verify MongoDB connection
      env:
        MDB_URI: ${{ secrets.MDB_URI }}
      run: |
        cd backend
        python mongodb_handler.py
    
    - name: Run disaster tweet pipeline
      env:
        BLUESKY_USER: ${{ secrets.BLUESKY_USER }}
        BLUESKY_PWD: ${{ secrets.BLUESKY_PWD }}
        HF_TOKEN1: ${{ secrets.HF_TOKEN1 }}
        HF_TOKEN2: ${{ secrets.HF_TOKEN2 }}
        HF_TOKEN3: ${{ secrets.HF_TOKEN3 }}
        HF_TOKEN4: ${{ secrets.HF_TOKEN4 }}
        HF_TOKEN5: ${{ secrets.HF_TOKEN5 }}
        HF_TOKEN6: ${{ secrets.HF_TOKEN6 }}
        HF_TOKEN7: ${{ secrets.HF_TOKEN7 }}
        HF_TOKEN8: ${{ secrets.HF_TOKEN8 }}
        HF_TOKEN9: ${{ secrets.HF_TOKEN9 }}
        HF_TOKEN10: ${{ secrets.HF_TOKEN10 }}
        HF_TOKEN11: ${{ secrets.HF_TOKEN11 }}
        MDB_URI: ${{ secrets.MDB_URI }}
      run: |
        cd backend
        echo "Starting unified pipeline..."
        python unified_pipeline.py
        
        echo "Processing incidents and uploading to MongoDB..."
        python regenerate_incidents.py
    
    - name: Check MongoDB upload status
      if: success()
      env:
        MDB_URI: ${{ secrets.MDB_URI }}
      run: |
        cd backend
        python -c "
        from mongodb_handler import MongoDBHandler
        handler = MongoDBHandler()
        if handler.connect():
            stats = handler.get_statistics()
            print(f'üìä MongoDB Statistics:')
            print(f'   Total incidents: {stats[\"total_incidents\"]}')
            print(f'   Active incidents: {stats[\"active_incidents\"]}')
            print(f'   By type: {stats[\"by_type\"]}')
            handler.close()
        else:
            print('‚ö†Ô∏è Could not verify MongoDB upload')
        "
    
    - name: Upload pipeline results as artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: pipeline-results-${{ github.run_number }}
        path: |
          backend/pipeline_output/
          backend/incidents.json
        retention-days: 30
    
    - name: Create summary
      if: always()
      run: |
        cd backend
        echo "## üìä Pipeline Run Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Run Time:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
        echo "**Status:** ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -f pipeline_output/04_final_results.jsonl ]; then
          TWEET_COUNT=$(wc -l < pipeline_output/04_final_results.jsonl)
          echo "**Tweets Processed:** $TWEET_COUNT" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ -f incidents.json ]; then
          INCIDENT_COUNT=$(python -c "import json; data=json.load(open('incidents.json')); print(len(data.get('incidents', [])))")
          echo "**Incidents Created:** $INCIDENT_COUNT" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### üìÅ Output Files" >> $GITHUB_STEP_SUMMARY
        echo "- Raw tweets: \`pipeline_output/01_raw_tweets.jsonl\`" >> $GITHUB_STEP_SUMMARY
        echo "- Cleaned tweets: \`pipeline_output/02_cleaned_tweets.jsonl\`" >> $GITHUB_STEP_SUMMARY
        echo "- ML classifications: \`pipeline_output/03_classified_tweets.jsonl\`" >> $GITHUB_STEP_SUMMARY
        echo "- LLM validations: \`pipeline_output/04_final_results.jsonl\`" >> $GITHUB_STEP_SUMMARY
        echo "- Final incidents: \`incidents.json\`" >> $GITHUB_STEP_SUMMARY
        echo "- **MongoDB**: Incidents uploaded to \`lighthouse.incidents\` collection" >> $GITHUB_STEP_SUMMARY

    
 #   - name: Optional - Commit results to repo
 #     if: success()
 #     continue-on-error: true
 #     run: |
 #       cd backend
 #       git config --local user.email "github-actions[bot]@users.noreply.github.com"
 #       git config --local user.name "github-actions[bot]"
        
 #       # Only commit the final incidents.json (pipeline_output is temp)
 #       git add incidents.json || true
        
 #       if ! git diff --staged --quiet; then
 #         git commit -m "ü§ñ Auto-update: Pipeline run $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
 #         git push
 #       else
 #         echo "No changes to commit"
 #       fi
 #     env:
 #       GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Report final status
      if: always()
      run: |
        echo "=================================="
        if [ "${{ job.status }}" == "success" ]; then
          echo "‚úÖ Pipeline completed successfully"
          echo "‚úÖ Tweets fetched and classified"
          echo "‚úÖ Incidents uploaded to MongoDB"
          echo "‚úÖ Results available in artifacts"
        else
          echo "‚ùå Pipeline failed"
          echo "Check logs above for error details"
          exit 1
        fi
        echo "=================================="
